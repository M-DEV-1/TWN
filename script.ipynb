{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents:\n",
      "#ID\tSynset_name\tPOS\tSynset_gloss  Prob_of_being_Past\tProb_of_being_Present\tProb_of_being_Future\tProb_of_being_Atemporal\n",
      "1740\table.a.01\ta\t(usually followed by `to') having the necessary means or skill or know-how or authority to do something\t0.0\t0.002\t0.998\t0\n",
      "2098\tunable.a.01\ta\t(usually followed by `to') not having the necessary means or skill or know-how\t0.0\t0.001798\t0.897202\t0.101\n",
      "2312\tabaxial.a.01\ta\tfacing away from the axis of an organ or organism\t0.004\t0.345\t0.651\t0\n",
      "2527\tadaxial.a.01\ta\tnearest to or facing toward the axis of an organ or organism\t0.002\t0.0\t0.998\t0\n"
     ]
    }
   ],
   "source": [
    "# Temporary: Check if file is read correctly.\n",
    "# Will be removed in final version.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# returns the first 5 lines of the dataset, including the titleheader\n",
    "def peek_file(file_path, num_lines=5):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for _ in range(num_lines):\n",
    "            print(file.readline().strip())\n",
    "\n",
    "print(\"File contents:\")\n",
    "peek_file('./TempoWordNet/TempoWnL_1.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117654 entries, 0 to 117653\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   ID                       117654 non-null  object\n",
      " 1   Synset_name              117654 non-null  object\n",
      " 2   POS                      117654 non-null  object\n",
      " 3   Synset_gloss             117654 non-null  object\n",
      " 4   Prob_of_being_Past       117654 non-null  object\n",
      " 5   Prob_of_being_Present    117654 non-null  object\n",
      " 6   Prob_of_being_Future     117654 non-null  object\n",
      " 7   Prob_of_being_Atemporal  117654 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 7.2+ MB\n",
      "None\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "     ID      Synset_name POS  \\\n",
      "0  1740        able.a.01   a   \n",
      "1  2098      unable.a.01   a   \n",
      "2  2312     abaxial.a.01   a   \n",
      "3  2527     adaxial.a.01   a   \n",
      "4  2730  acroscopic.a.01   a   \n",
      "\n",
      "                                        Synset_gloss Prob_of_being_Past  \\\n",
      "0  (usually followed by `to') having the necessar...                0.0   \n",
      "1  (usually followed by `to') not having the nece...                0.0   \n",
      "2  facing away from the axis of an organ or organism              0.004   \n",
      "3  nearest to or facing toward the axis of an org...              0.002   \n",
      "4              facing or on the side toward the apex                0.0   \n",
      "\n",
      "  Prob_of_being_Present Prob_of_being_Future Prob_of_being_Atemporal  \n",
      "0                 0.002                0.998                       0  \n",
      "1              0.001798             0.897202                   0.101  \n",
      "2                 0.345                0.651                       0  \n",
      "3                   0.0                0.998                       0  \n",
      "4                 0.002                0.998                       0  \n"
     ]
    }
   ],
   "source": [
    "# Temporary: Check if probability is extracted properly.\n",
    "# Will be removed in final version.\n",
    "\n",
    "def read_tempowordnet_manually(file_path):\n",
    "    # initiliase empty data list\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Skip comments\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            # This code is not required anymore since the code was manually cleaned for comments\n",
    "            \n",
    "            # Manually split the line\n",
    "            # Strips leading and trailing whitespace from the line and then splits it into a list of words (or fields) using whitespace as the delimiter.\n",
    "            # split_line = line.strip().split()\n",
    "            split_line = line.strip().split('\\t')\n",
    "\n",
    "            # Extract the temporal probability fields from the end\n",
    "            # OLD! - newer versions use a different logic as the dataset was cleaned (regex)\n",
    "            if len(split_line) >= 8:\n",
    "                id_field = split_line[0]\n",
    "                synset_name_field = split_line[1]\n",
    "                pos_field = split_line[2]\n",
    "                \n",
    "                # Gloss is all fields between POS and the first probability field\n",
    "                gloss_field = ' '.join(split_line[3:-4])\n",
    "                \n",
    "                # Temporal probability fields\n",
    "                prob_past = split_line[-4]\n",
    "                prob_present = split_line[-3]\n",
    "                prob_future = split_line[-2]\n",
    "                prob_atemporal = split_line[-1]\n",
    "                \n",
    "                # Construct row data\n",
    "                row = {\n",
    "                    \"ID\": id_field,\n",
    "                    \"Synset_name\": synset_name_field,\n",
    "                    \"POS\": pos_field,\n",
    "                    \"Synset_gloss\": gloss_field,\n",
    "                    \"Prob_of_being_Past\": prob_past,\n",
    "                    \"Prob_of_being_Present\": prob_present,\n",
    "                    \"Prob_of_being_Future\": prob_future,\n",
    "                    \"Prob_of_being_Atemporal\": prob_atemporal\n",
    "                }\n",
    "                data.append(row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "tempowordnet_df = read_tempowordnet_manually('./TempoWordNet/TempoWnL_1.0.txt')\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(tempowordnet_df.info())\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(tempowordnet_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117654 entries, 0 to 117653\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   ID                       117654 non-null  object \n",
      " 1   Synset_name              117654 non-null  object \n",
      " 2   POS                      117654 non-null  object \n",
      " 3   Synset_gloss             117654 non-null  object \n",
      " 4   Prob_of_being_Past       117654 non-null  float64\n",
      " 5   Prob_of_being_Present    117654 non-null  float64\n",
      " 6   Prob_of_being_Future     117654 non-null  float64\n",
      " 7   Prob_of_being_Atemporal  117654 non-null  float64\n",
      " 8   Word                     117654 non-null  object \n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 8.1+ MB\n",
      "None\n",
      "\n",
      "First few rows of the updated DataFrame:\n",
      "     ID      Synset_name POS  \\\n",
      "0  1740        able.a.01   a   \n",
      "1  2098      unable.a.01   a   \n",
      "2  2312     abaxial.a.01   a   \n",
      "3  2527     adaxial.a.01   a   \n",
      "4  2730  acroscopic.a.01   a   \n",
      "\n",
      "                                        Synset_gloss  Prob_of_being_Past  \\\n",
      "0  (usually followed by `to') having the necessar...               0.000   \n",
      "1  (usually followed by `to') not having the nece...               0.000   \n",
      "2  facing away from the axis of an organ or organism               0.004   \n",
      "3  nearest to or facing toward the axis of an org...               0.002   \n",
      "4              facing or on the side toward the apex               0.000   \n",
      "\n",
      "   Prob_of_being_Present  Prob_of_being_Future  Prob_of_being_Atemporal  \\\n",
      "0               0.002000              0.998000                    0.000   \n",
      "1               0.001798              0.897202                    0.101   \n",
      "2               0.345000              0.651000                    0.000   \n",
      "3               0.000000              0.998000                    0.000   \n",
      "4               0.002000              0.998000                    0.000   \n",
      "\n",
      "         Word  \n",
      "0        able  \n",
      "1      unable  \n",
      "2     abaxial  \n",
      "3     adaxial  \n",
      "4  acroscopic  \n"
     ]
    }
   ],
   "source": [
    "# Create 'Word' column\n",
    "tempowordnet_df['Word'] = tempowordnet_df['Synset_name'].str.split('.').str[0]\n",
    "\n",
    "# Convert probability columns to numeric\n",
    "prob_columns = [\"Prob_of_being_Past\", \"Prob_of_being_Present\", \"Prob_of_being_Future\", \"Prob_of_being_Atemporal\"]\n",
    "for col in prob_columns:\n",
    "    tempowordnet_df[col] = pd.to_numeric(tempowordnet_df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nUpdated DataFrame Info:\")\n",
    "print(tempowordnet_df.info())\n",
    "print(\"\\nFirst few rows of the updated DataFrame:\")\n",
    "print(tempowordnet_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize lemmatizer and stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to read TempoWordNet manually\n",
    "def read_tempowordnet_manually(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            split_line = line.strip().split()\n",
    "            \n",
    "            # replace space in .txt file with \\t - regex    \n",
    "            if len(split_line) >= 8:\n",
    "                try:\n",
    "                    id_field = split_line[0]\n",
    "                    synset_name_field = split_line[1]\n",
    "                    pos_field = split_line[2]\n",
    "                    gloss_field = ' '.join(split_line[3:-4])\n",
    "                    prob_past = split_line[-4]\n",
    "                    prob_present = split_line[-3]\n",
    "                    prob_future = split_line[-2]\n",
    "                    prob_atemporal = split_line[-1]\n",
    "                    row = {\n",
    "                        \"ID\": id_field,\n",
    "                        \"Synset_name\": synset_name_field,\n",
    "                        \"POS\": pos_field,\n",
    "                        \"Synset_gloss\": gloss_field,\n",
    "                        \"Prob_of_being_Past\": prob_past,\n",
    "                        \"Prob_of_being_Present\": prob_present,\n",
    "                        \"Prob_of_being_Future\": prob_future,\n",
    "                        \"Prob_of_being_Atemporal\": prob_atemporal\n",
    "                    }\n",
    "                    data.append(row)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {line}\")\n",
    "                    print(f\"Exception: {e}\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"Prob_of_being_Past\"] = pd.to_numeric(df[\"Prob_of_being_Past\"], errors='coerce')\n",
    "    df[\"Prob_of_being_Present\"] = pd.to_numeric(df[\"Prob_of_being_Present\"], errors='coerce')\n",
    "    df[\"Prob_of_being_Future\"] = pd.to_numeric(df[\"Prob_of_being_Future\"], errors='coerce')\n",
    "    df[\"Prob_of_being_Atemporal\"] = pd.to_numeric(df[\"Prob_of_being_Atemporal\"], errors='coerce')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the input text\n",
    "def preprocess_text(text):\n",
    "    # nltk.tokenize, split input text into tokens\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # filter out stopwords from the words list\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    # words = [stemmer.stem(lemmatizer.lemmatize(word)) for word in words]\n",
    "    # older version where both lemmatization and stemming was happening\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average temporal probabilities and extract IDs\n",
    "def calculate_temporal_probabilities(words, df):\n",
    "    temporal_probs = [] # to store tuples of temporal probabilities for each word\n",
    "    \n",
    "    ids = [] # id of each word used to calculate temp.prob\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            # case-sensitive substring search to find the word in the words list\n",
    "            matches = df[df['Synset_name'].str.contains(word)]\n",
    "            if not matches.empty:\n",
    "                for _, row in matches.iterrows():\n",
    "                    # tuple creation, and append to main lists\n",
    "                    probs = (row['Prob_of_being_Past'], row['Prob_of_being_Present'], row['Prob_of_being_Future'], row['Prob_of_being_Atemporal'])\n",
    "                    temporal_probs.append(probs)\n",
    "                    ids.append(row['ID'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing word: {word}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "    \n",
    "    # if any probabilites are collected in temporal_probs list\n",
    "    if temporal_probs:\n",
    "        # return average probability and the id\n",
    "        # FUTURE!   consider changing average to weighted mean or any other method \n",
    "        avg_probs = np.mean(temporal_probs, axis=0)\n",
    "        return avg_probs, ids\n",
    "    else:\n",
    "        return None, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the input sentence\n",
    "def process_sentence(sentence, df):\n",
    "    words = preprocess_text(sentence)\n",
    "    avg_probs, ids = calculate_temporal_probabilities(words, df)\n",
    "    return words, avg_probs, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to processed_results.txt.\n"
     ]
    }
   ],
   "source": [
    "# Path to your TempoWordNet file\n",
    "file_path = './TempoWordNet/TempoWnL_1.0.txt'\n",
    "tempowordnet_df = read_tempowordnet_manually(file_path)\n",
    "\n",
    "# Input sentence\n",
    "sentence = input('Input sentence for processing: ')\n",
    "\n",
    "# Process the sentence\n",
    "preprocessed_text, avg_temporal_probs, ids = process_sentence(sentence, tempowordnet_df)\n",
    "\n",
    "# Append results to a text file\n",
    "output_file_path = 'processed_results.txt'\n",
    "with open(output_file_path, 'a', encoding='utf-8') as file:\n",
    "    file.write(f\"\\n{'-'*50}\\n\")\n",
    "    file.write(f\"Original Sentence:\\n{sentence}\\n\\n\")\n",
    "    file.write(f\"Preprocessed Text:\\n{' '.join(preprocessed_text)}\\n\\n\")\n",
    "    if avg_temporal_probs is not None:\n",
    "        file.write(f\"{'ID':<15} {'Past':<10} {'Present':<10} {'Future':<10} {'Atemporal':<10}\\n\")\n",
    "        file.write(f\"{'-'*50}\\n\")\n",
    "        for id in ids:\n",
    "            match = tempowordnet_df[tempowordnet_df['ID'] == id].iloc[0]\n",
    "            file.write(f\"{id:<15} {match['Prob_of_being_Past']:<10.6f} {match['Prob_of_being_Present']:<10.6f} {match['Prob_of_being_Future']:<10.6f} {match['Prob_of_being_Atemporal']:<10.6f}\\n\")\n",
    "        file.write(f\"\\nAverage Temporal Probabilities:\\n\")\n",
    "        file.write(f\"Past: {avg_temporal_probs[0]:.6f}\\n\")\n",
    "        file.write(f\"Present: {avg_temporal_probs[1]:.6f}\\n\")\n",
    "        file.write(f\"Future: {avg_temporal_probs[2]:.6f}\\n\")\n",
    "        file.write(f\"Atemporal: {avg_temporal_probs[3]:.6f}\\n\")\n",
    "    else:\n",
    "        file.write(\"No valid words found in TempoWordNet.\\n\")\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
