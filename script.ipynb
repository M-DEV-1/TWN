{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents:\n",
      "#ID    Name    POS   Gloss  Prob_of_being_Past    Prob_of_being_Present    Prob_of_being_Future    Prob_of_being_Atemporal\n",
      "1740    able.a.01    a    (usually followed by `to') having the necessary means or skill or know-how or authority to do something    0.000000   0.000238   0.118762   0.881\n",
      "2098    unable.a.01    a    (usually followed by `to') not having the necessary means or skill or know-how    0.000000   0.001728   0.862272   0.136\n",
      "2312    abaxial.a.01    a    facing away from the axis of an organ or organism    0.000000   0.149700   0.000300   0.85\n",
      "2527    adaxial.a.01    a    nearest to or facing toward the axis of an organ or organism    0.000000   0.700596   0.001404   0.298\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def peek_file(file_path, num_lines=5):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for _ in range(num_lines):\n",
    "            print(file.readline().strip())\n",
    "\n",
    "print(\"File contents:\")\n",
    "peek_file('./TempoWordNet/TempoWnL_1.0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117658 entries, 0 to 117657\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   ID                       117658 non-null  object\n",
      " 1   Synset_name              117658 non-null  object\n",
      " 2   POS                      117658 non-null  object\n",
      " 3   Synset_gloss             117658 non-null  object\n",
      " 4   Prob_of_being_Past       117658 non-null  object\n",
      " 5   Prob_of_being_Present    117658 non-null  object\n",
      " 6   Prob_of_being_Future     117658 non-null  object\n",
      " 7   Prob_of_being_Atemporal  117658 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 7.2+ MB\n",
      "None\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "     ID      Synset_name POS  \\\n",
      "0  1740        able.a.01   a   \n",
      "1  2098      unable.a.01   a   \n",
      "2  2312     abaxial.a.01   a   \n",
      "3  2527     adaxial.a.01   a   \n",
      "4  2730  acroscopic.a.01   a   \n",
      "\n",
      "                                        Synset_gloss Prob_of_being_Past  \\\n",
      "0  (usually followed by `to') having the necessar...           0.000000   \n",
      "1  (usually followed by `to') not having the nece...           0.000000   \n",
      "2  facing away from the axis of an organ or organism           0.000000   \n",
      "3  nearest to or facing toward the axis of an org...           0.000000   \n",
      "4              facing or on the side toward the apex           0.000000   \n",
      "\n",
      "  Prob_of_being_Present Prob_of_being_Future Prob_of_being_Atemporal  \n",
      "0              0.000238             0.118762                   0.881  \n",
      "1              0.001728             0.862272                   0.136  \n",
      "2              0.149700             0.000300                    0.85  \n",
      "3              0.700596             0.001404                   0.298  \n",
      "4              0.700596             0.001404                   0.298  \n"
     ]
    }
   ],
   "source": [
    "def read_tempowordnet_manually(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # Skip comments\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            \n",
    "            # Manually split the line\n",
    "            split_line = line.strip().split()\n",
    "\n",
    "            # Extract the temporal probability fields from the end\n",
    "            if len(split_line) >= 8:\n",
    "                id_field = split_line[0]\n",
    "                synset_name_field = split_line[1]\n",
    "                pos_field = split_line[2]\n",
    "                \n",
    "                # Gloss is all fields between POS and the first probability field\n",
    "                gloss_field = ' '.join(split_line[3:-4])\n",
    "                \n",
    "                # Temporal probability fields\n",
    "                prob_past = split_line[-4]\n",
    "                prob_present = split_line[-3]\n",
    "                prob_future = split_line[-2]\n",
    "                prob_atemporal = split_line[-1]\n",
    "                \n",
    "                # Construct row data\n",
    "                row = {\n",
    "                    \"ID\": id_field,\n",
    "                    \"Synset_name\": synset_name_field,\n",
    "                    \"POS\": pos_field,\n",
    "                    \"Synset_gloss\": gloss_field,\n",
    "                    \"Prob_of_being_Past\": prob_past,\n",
    "                    \"Prob_of_being_Present\": prob_present,\n",
    "                    \"Prob_of_being_Future\": prob_future,\n",
    "                    \"Prob_of_being_Atemporal\": prob_atemporal\n",
    "                }\n",
    "                data.append(row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "tempowordnet_df = read_tempowordnet_manually('./TempoWordNet/TempoWnL_1.0.txt')\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(tempowordnet_df.info())\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(tempowordnet_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117658 entries, 0 to 117657\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   ID                       117658 non-null  object \n",
      " 1   Synset_name              117658 non-null  object \n",
      " 2   POS                      117658 non-null  object \n",
      " 3   Synset_gloss             117658 non-null  object \n",
      " 4   Prob_of_being_Past       117658 non-null  float64\n",
      " 5   Prob_of_being_Present    117658 non-null  float64\n",
      " 6   Prob_of_being_Future     117658 non-null  float64\n",
      " 7   Prob_of_being_Atemporal  117658 non-null  float64\n",
      " 8   Word                     117658 non-null  object \n",
      "dtypes: float64(4), object(5)\n",
      "memory usage: 8.1+ MB\n",
      "None\n",
      "\n",
      "First few rows of the updated DataFrame:\n",
      "     ID      Synset_name POS  \\\n",
      "0  1740        able.a.01   a   \n",
      "1  2098      unable.a.01   a   \n",
      "2  2312     abaxial.a.01   a   \n",
      "3  2527     adaxial.a.01   a   \n",
      "4  2730  acroscopic.a.01   a   \n",
      "\n",
      "                                        Synset_gloss  Prob_of_being_Past  \\\n",
      "0  (usually followed by `to') having the necessar...                 0.0   \n",
      "1  (usually followed by `to') not having the nece...                 0.0   \n",
      "2  facing away from the axis of an organ or organism                 0.0   \n",
      "3  nearest to or facing toward the axis of an org...                 0.0   \n",
      "4              facing or on the side toward the apex                 0.0   \n",
      "\n",
      "   Prob_of_being_Present  Prob_of_being_Future  Prob_of_being_Atemporal  \\\n",
      "0               0.000238              0.118762                    0.881   \n",
      "1               0.001728              0.862272                    0.136   \n",
      "2               0.149700              0.000300                    0.850   \n",
      "3               0.700596              0.001404                    0.298   \n",
      "4               0.700596              0.001404                    0.298   \n",
      "\n",
      "         Word  \n",
      "0        able  \n",
      "1      unable  \n",
      "2     abaxial  \n",
      "3     adaxial  \n",
      "4  acroscopic  \n"
     ]
    }
   ],
   "source": [
    "# Create 'Word' column\n",
    "tempowordnet_df['Word'] = tempowordnet_df['Synset_name'].str.split('.').str[0]\n",
    "\n",
    "# Convert probability columns to numeric\n",
    "prob_columns = [\"Prob_of_being_Past\", \"Prob_of_being_Present\", \"Prob_of_being_Future\", \"Prob_of_being_Atemporal\"]\n",
    "for col in prob_columns:\n",
    "    tempowordnet_df[col] = pd.to_numeric(tempowordnet_df[col], errors='coerce')\n",
    "\n",
    "print(\"\\nUpdated DataFrame Info:\")\n",
    "print(tempowordnet_df.info())\n",
    "print(\"\\nFirst few rows of the updated DataFrame:\")\n",
    "print(tempowordnet_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to processed_results.txt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize lemmatizer and stemmer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to read TempoWordNet manually\n",
    "def read_tempowordnet_manually(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            split_line = line.strip().split()\n",
    "            \n",
    "            # replace space in .txt file with \\t - regex    \n",
    "            if len(split_line) >= 8:\n",
    "                try:\n",
    "                    id_field = split_line[0]\n",
    "                    synset_name_field = split_line[1]\n",
    "                    pos_field = split_line[2]\n",
    "                    gloss_field = ' '.join(split_line[3:-4])\n",
    "                    prob_past = split_line[-4]\n",
    "                    prob_present = split_line[-3]\n",
    "                    prob_future = split_line[-2]\n",
    "                    prob_atemporal = split_line[-1]\n",
    "                    row = {\n",
    "                        \"ID\": id_field,\n",
    "                        \"Synset_name\": synset_name_field,\n",
    "                        \"POS\": pos_field,\n",
    "                        \"Synset_gloss\": gloss_field,\n",
    "                        \"Prob_of_being_Past\": prob_past,\n",
    "                        \"Prob_of_being_Present\": prob_present,\n",
    "                        \"Prob_of_being_Future\": prob_future,\n",
    "                        \"Prob_of_being_Atemporal\": prob_atemporal\n",
    "                    }\n",
    "                    data.append(row)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {line}\")\n",
    "                    print(f\"Exception: {e}\")\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"Prob_of_being_Past\"] = pd.to_numeric(df[\"Prob_of_being_Past\"], errors='coerce')\n",
    "    df[\"Prob_of_being_Present\"] = pd.to_numeric(df[\"Prob_of_being_Present\"], errors='coerce')\n",
    "    df[\"Prob_of_being_Future\"] = pd.to_numeric(df[\"Prob_of_being_Future\"], errors='coerce')\n",
    "    df[\"Prob_of_being_Atemporal\"] = pd.to_numeric(df[\"Prob_of_being_Atemporal\"], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Preprocess the input text\n",
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    words = [stemmer.stem(lemmatizer.lemmatize(word)) for word in words]\n",
    "    return words\n",
    "\n",
    "# Calculate average temporal probabilities and extract IDs\n",
    "def calculate_temporal_probabilities(words, df):\n",
    "    temporal_probs = []\n",
    "    ids = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            matches = df[df['Synset_name'].str.contains(word)]\n",
    "            if not matches.empty:\n",
    "                for _, row in matches.iterrows():\n",
    "                    probs = (row['Prob_of_being_Past'], row['Prob_of_being_Present'], row['Prob_of_being_Future'], row['Prob_of_being_Atemporal'])\n",
    "                    temporal_probs.append(probs)\n",
    "                    ids.append(row['ID'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing word: {word}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "    \n",
    "    if temporal_probs:\n",
    "        avg_probs = np.mean(temporal_probs, axis=0)\n",
    "        return avg_probs, ids\n",
    "    else:\n",
    "        return None, []\n",
    "\n",
    "# Process the input sentence\n",
    "def process_sentence(sentence, df):\n",
    "    words = preprocess_text(sentence)\n",
    "    avg_probs, ids = calculate_temporal_probabilities(words, df)\n",
    "    return words, avg_probs, ids\n",
    "\n",
    "# Path to your TempoWordNet file\n",
    "file_path = './TempoWordNet/TempoWnL_1.0.txt'\n",
    "tempowordnet_df = read_tempowordnet_manually(file_path)\n",
    "\n",
    "# Input sentence\n",
    "sentence = input('Input sentence for processing: ')\n",
    "\n",
    "# Process the sentence\n",
    "preprocessed_text, avg_temporal_probs, ids = process_sentence(sentence, tempowordnet_df)\n",
    "\n",
    "# Append results to a text file\n",
    "output_file_path = 'processed_results.txt'\n",
    "with open(output_file_path, 'a', encoding='utf-8') as file:\n",
    "    file.write(f\"\\n{'-'*50}\\n\")\n",
    "    file.write(f\"Original Sentence:\\n{sentence}\\n\\n\")\n",
    "    file.write(f\"Preprocessed Text:\\n{' '.join(preprocessed_text)}\\n\\n\")\n",
    "    if avg_temporal_probs is not None:\n",
    "        file.write(f\"{'ID':<15} {'Past':<10} {'Present':<10} {'Future':<10} {'Atemporal':<10}\\n\")\n",
    "        file.write(f\"{'-'*50}\\n\")\n",
    "        for id in ids:\n",
    "            match = tempowordnet_df[tempowordnet_df['ID'] == id].iloc[0]\n",
    "            file.write(f\"{id:<15} {match['Prob_of_being_Past']:<10.6f} {match['Prob_of_being_Present']:<10.6f} {match['Prob_of_being_Future']:<10.6f} {match['Prob_of_being_Atemporal']:<10.6f}\\n\")\n",
    "        file.write(f\"\\nAverage Temporal Probabilities:\\n\")\n",
    "        file.write(f\"Past: {avg_temporal_probs[0]:.6f}\\n\")\n",
    "        file.write(f\"Present: {avg_temporal_probs[1]:.6f}\\n\")\n",
    "        file.write(f\"Future: {avg_temporal_probs[2]:.6f}\\n\")\n",
    "        file.write(f\"Atemporal: {avg_temporal_probs[3]:.6f}\\n\")\n",
    "    else:\n",
    "        file.write(\"No valid words found in TempoWordNet.\\n\")\n",
    "\n",
    "print(f\"Results have been saved to {output_file_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
